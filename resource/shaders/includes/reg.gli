// register file for simple dx8 style shader VM
//
// the packing/unpacking might be potentially be an issue on dx10 era/VLIW hardware or mobile (lol mobile)
// this should eventually be tested and changes made as needed (or even a simple alternative path with fixed shading)
// ....what I would give for packed math support or 8 bit arithmetic on older gpus *sobs*

import "defines.gli"
import "uniforms.gli"
import "math.gli"
import "isa.gli"
import "attr.gli"

#ifndef REG_H
#define REG_H

#ifdef FRAGMENT_SHADER

// todo: this should be permutations
#ifdef REFRACTION
#define REG_COUNT    6
#else
#define REG_COUNT    3
#endif

uint s_lodbias;

// registers
uint  vdir;         //    16:16 - tangent space view dir
uint  r[REG_COUNT]; // flexible - temp registers (rgba8, rg16f, r32f)
uint  v[COLOR_SETS]; // 8:8:8:8 - color registers (tone mapped)

uvec2 vpos;			   // 16:16:16:16 - view space position + depth
vec2 tr[UV_SETS]; // 32:32 - texture coordinate registers

vec2 packTexcoordRegister(vec2 unpackedInput)
{
	return unpackedInput.xy;//packHalf2x16(unpackedInput.xy - 0.5);
}

vec2 read_texcoord_reg(uint i)
{
	return tr[i];//unpackHalf2x16(tr[i]).xy + 0.5;
}

uint pack_vertex_reg(vec4 unpackedInput)
{
	//unpackedInput.rgb = fastExp2(-unpackedInput.rgb);
	return packUnorm4x8(unpackedInput);
}

vec4 unpack_vertex_reg(uint packedInput)
{
	vec4 v = unpackUnorm4x8(packedInput);
//	v.rgb = -fastLog2(v.rgb);
	return v;
}

vec4 read_color_reg(uint i)
{
	return unpack_vertex_reg(v[i]);
}

vec3 read_vpos()
{
	return unpackHalf4x16(vpos).xyz;
}

float read_z()
{
	return unpackHalf4x16(vpos).w;
}

uint swizzle_comp(uint s_swizzle, uint idx)
{
	return (s_swizzle >> (idx << 1)) & 0x03;
}

vec4 swizzle_reg(vec4 reg, uint s_swizzle)
{
	vec4 result;
	result.x = reg[swizzle_comp(s_swizzle, 0)];
	result.y = reg[swizzle_comp(s_swizzle, 1)];
	result.z = reg[swizzle_comp(s_swizzle, 2)];
	result.w = reg[swizzle_comp(s_swizzle, 3)];
	return result;
}

vec4 decode_reg(uint reg, uint s_fmt)
{
	switch(s_fmt)
	{
	default:
	case REG_U8:	return unpackUnorm4x8(reg);
	case REG_S8:	return unpackSnorm4x8(reg);
	case REG_F16:	return vec4( unpackHalf2x16(reg), 0, 0);
	case REG_F32:	return vec4( uintBitsToFloat(reg) );
	}
}

uint encode_reg(vec4 reg, uint s_fmt)
{
	switch(s_fmt)
	{
	default:
	case REG_U8:	return packUnorm4x8(reg);
	case REG_S8:	return packSnorm4x8(reg);
	case REG_F16:	return packHalf2x16(reg.xy);
	case REG_F32:	return floatBitsToUint(reg.x);
	}
}

vec4 read_system_value(uint s_addr)
{
	switch(s_addr)
	{
	default:							return vec4(0.0);
	case SHADER_SYS_TIME:				return vec4(timeSeconds);
	case SHADER_SYS_XY:					return vec4(gl_FragCoord.xy, 0, 0);
	case SHADER_SYS_Z:					return vec4(read_z());
	case SHADER_SYS_POS:				return vec4(read_vpos(), 0.0);
	case SHADER_SYS_UV:					return vec4(gl_FragCoord.xy / iResolution.xy, 0, 0);
	case SHADER_SYS_AR:					return vec4(gl_FragCoord.y / gl_FragCoord.x, 1.0, 0, 0);
	case SHADER_SYS_TEXSIZE:			return vec4(texsize.xy, 0, 0);
		// material registers
	case SHADER_SYS_MAT_FILL:			return fillColor;
	case SHADER_SYS_MAT_ALBEDO:			return albedoFactor;
	case SHADER_SYS_MAT_EMISSIVE:		return emissiveFactor;
	case SHADER_SYS_MAT_SPECULAR:		return specularFactor;
	case SHADER_SYS_MAT_ROUGHNESS:		return vec4(roughnessFactor);
	case SHADER_SYS_MAT_DISPLACEMENT:	return vec4(displacement_factor);
	}
}

vec4 fetch_reg(vm_src s_operand, uint s_imm)
{
	switch(s_operand.type)
	{
	default:			 return vec4(0.0);
	case REG_TYPE_GPR:	 return decode_reg(r[s_operand.addr], s_operand.fmt);
	case REG_TYPE_CLR:	 return read_color_reg(s_operand.addr);
	case REG_TYPE_CON:	 return shaderConstants[s_operand.addr];
	case REG_TYPE_TEX:	 return read_texcoord_reg(s_operand.addr).xyxy;
	case REG_TYPE_IMM8:	 return vec4(unpackUnorm4x8(s_operand.addr).x);
	case REG_TYPE_IMM16: return vec4(unpackHalf2x16(s_imm >> (s_operand.idx << 4)).x);
	case REG_TYPE_SYS:   return read_system_value(s_operand.addr);
	}
}

vec4 apply_reduction(vec4 reg, uint s_reduction)
{
	switch(s_reduction)
	{
	default:			return reg;
	case SRC_RED_LUM:	return vec4( dot(reg.rgb, vec3(0.2125, 0.7154, 0.0721)) );
	case SRC_RED_SUM:	return vec4( reg.r + reg.g + reg.b );
	case SRC_RED_AVG:	return vec4( (reg.r + reg.g + reg.b) * 0.3333 );
	case SRC_RED_MIN:	return vec4( min3(reg.r, reg.g, reg.b) );
	case SRC_RED_MAX:	return vec4( max3(reg.r, reg.g, reg.b) );
	case SRC_RED_MAG:	return vec4( fastLength(reg.rgb) );
	}
}

vec4 read_src(vm_src s_operand, vm_instr s_ir)
{
	// fetch the relevant register or immediate value
	vec4 reg = fetch_reg(s_operand, s_ir.imm);

	// apply swizzle
	reg = swizzle_reg(reg, s_operand.swizzle);
	
	// branchless scale + bias
	reg = reg * aScaleBias[s_operand.scale_bias].x + aScaleBias[s_operand.scale_bias].y;
	
	// modifiers
	if( s_operand.absolute)	reg = abs(reg);
	
	// branchless negate or invert
	reg = reg * aNegInv[s_operand.neg_inv].x + aNegInv[s_operand.neg_inv].y;

	return apply_reduction(reg, s_operand.reduction);
}

vec4 read_src0(vm_instr s_ir)
{
	return read_src(s_ir.src0, s_ir);
}

vec4 read_src1(vm_instr s_ir)
{
	return read_src(s_ir.src1, s_ir);
}

vec4 read_src2(vm_instr s_ir)
{
	return read_src(s_ir.src2, s_ir);
}

void write_reg(vm_instr s_ir, vec4 reg)
{
	// clear the masked bits
	r[s_ir.dst.addr] &= ~s_ir.dst.mask;

	// swizzle for the destination
	reg = swizzle_reg(reg, s_ir.dst.swizzle);

	// branchless multiplier
	reg *= aScaleBias[s_ir.dst.multiplier].x;

	// modifiers
	if (s_ir.dst.absolute)	reg = abs(reg);
	if (s_ir.sat)			reg = sat4(reg);
	if (s_ir.dst.negate)	reg = -reg;

	// encode
	uint p = encode_reg(reg, s_ir.dst.fmt);

	// write the masked bits
	r[s_ir.dst.addr] |= (p & s_ir.dst.mask);
}

vec4 read_dest(vm_instr s_ir)
{
	return decode_reg(r[s_ir.dst.addr], s_ir.dst.fmt);
}

#endif

#endif
