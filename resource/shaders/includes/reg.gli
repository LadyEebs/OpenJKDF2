// register file for simple dx8 style shader VM
//
// the packing/unpacking might be potentially be an issue on dx10 era/VLIW hardware or mobile (lol mobile)
// this should eventually be tested and changes made as needed (or even a simple alternative path with fixed shading)
// ....what I would give for packed math support or 8 bit arithmetic on older gpus *sobs*

import "defines.gli"
import "uniforms.gli"
import "math.gli"
import "isa.gli"
import "attr.gli"

#ifndef REG_H
#define REG_H


#ifndef REG_COUNT
#	define REG_COUNT 2
#endif

uint s_lodbias;

// registers
uint  vnorm;            //    8:8:8:8 - view space normal + free 8 bits
uint  vdir;				//      16:16 - tangent space view dir
uint  r[REG_COUNT];		//   flexible - temp registers (rgba8, rg16f, r32f)
uint  v[COLOR_SETS];	//    8:8:8:8 - color registers (tone mapped)

vec2 tr[UV_SETS];		//       32:32 - texture coordinate registers
uvec2 vpos;				// 16:16:16:16 - view space position + depth

uvec2 packVPOS(vec4 v)
{
	return uvec2( packHalf2x16(v.xy), packHalf2x16(v.zw) );
}

vec4 readVPOS()
{
	return vec4( unpackHalf2x16(vpos.x).xy, unpackHalf2x16(vpos.y).xy );
}


vec2 packTexcoordRegister(vec2 unpackedInput)
{
	return unpackedInput.xy;//packHalf2x16(unpackedInput.xy - 0.5);
}

vec2 read_texcoord_reg(uint i)
{
	return tr[i];//unpackHalf2x16(tr[i]).xy + 0.5;
}

uint pack_vertex_reg(vec4 unpackedInput)
{
	unpackedInput.rgb = fastExp2(-unpackedInput.rgb);
	return packUnorm4x8(unpackedInput);
}

vec4 unpack_vertex_reg(uint packedInput)
{
	vec4 v = unpackUnorm4x8(packedInput);
	v.rgb = -fastLog2(v.rgb);
	return v;
}

vec4 read_color_reg(uint i)
{
	return unpack_vertex_reg(v[i]);
}

uint swizzle_comp(uint s_swizzle, uint idx)
{
	return (s_swizzle >> (idx << 1)) & 0x03;
}

vec4 swizzle_reg(vec4 reg, uint s_swizzle)
{
	vec4 result;
	result.x = reg[swizzle_comp(s_swizzle, 0)];
	result.y = reg[swizzle_comp(s_swizzle, 1)];
	result.z = reg[swizzle_comp(s_swizzle, 2)];
	result.w = reg[swizzle_comp(s_swizzle, 3)];
	return result;
}

vec4 decode_reg(uint reg, uint s_fmt)
{
	switch(s_fmt)
	{
	default:
	case REG_U8:	return unpackUnorm4x8(reg);
	case REG_S8:	return unpackSnorm4x8(reg);
	case REG_F16:	return vec4( unpackHalf2x16(reg), 0, 0);
	case REG_F32:	return vec4( uintBitsToFloat(reg) );
	}
}

uint encode_reg(vec4 reg, uint s_fmt)
{
	switch(s_fmt)
	{
	default:
	case REG_U8:	return packUnorm4x8(reg);
	case REG_S8:	return packSnorm4x8(reg);
	case REG_F16:	return packHalf2x16(reg.xy);
	case REG_F32:	return floatBitsToUint(reg.x);
	}
}

vec4 read_constant(uint s_addr)
{
	if (s_addr < 8)
		return shaderConstants[s_addr];

	switch(s_addr)
	{
	default:							return vec4(0.0);
	case SHADER_SYS_TIME:				return vec4(timeSeconds);
	case SHADER_SYS_Z:					return vec4(readVPOS().w);
	case SHADER_SYS_POS:				return vec4(readVPOS().xyz, 0.0);
	case SHADER_SYS_VDIR:				return vec4(normalize(-readVPOS().xyz), 0.0);
	case SHADER_SYS_NORM:				return vec4(unpackSnorm4x8(vnorm).xyz, 0.0);
	case SHADER_SYS_WPOS:				return vec4(transform44(viewMatrixInv, readVPOS().xyz), 1.0);
	case SHADER_SYS_WVDIR:				return vec4(mat3(viewMatrixInv) * normalize(-readVPOS().xyz), 0.0);
	case SHADER_SYS_WNORM:				return vec4(mat3(viewMatrixInv) * unpackSnorm4x8(vnorm).xyz, 1.0);
#ifdef FRAGMENT_SHADER
	case SHADER_SYS_XY:					return vec4(gl_FragCoord.xy, 0, 0);
	case SHADER_SYS_UV:					return vec4(gl_FragCoord.xy / iResolution.xy, 0, 0);
	case SHADER_SYS_AR:					return vec4(gl_FragCoord.y / gl_FragCoord.x, 1.0, 0, 0);
		// material registers
	case SHADER_SYS_MAT_FILL:			return fillColor;
	case SHADER_SYS_MAT_ALBEDO:			return albedoFactor;
	case SHADER_SYS_MAT_EMISSIVE:		return emissiveFactor;
	case SHADER_SYS_MAT_SPECULAR:		return specularFactor;
	case SHADER_SYS_MAT_ROUGHNESS:		return vec4(roughnessFactor);
	case SHADER_SYS_MAT_DISPLACEMENT:	return vec4(displacement_factor);
#endif
	}
}

vec4 fetch_reg(vm_src s_operand, uint s_imm)
{
	switch(s_operand.type)
	{
	default:				return vec4(0.0);
	case REG_TYPE_GPR:		return decode_reg(r[s_operand.addr], s_operand.fmt);
	case REG_TYPE_CLR:		return read_color_reg(s_operand.addr);
	case REG_TYPE_CON:		return read_constant(s_operand.addr);
	case REG_TYPE_TEX:		return read_texcoord_reg(s_operand.addr).xyxy;
	case REG_TYPE_IMM4x8:	return unpackSnorm4x8(s_imm);
	case REG_TYPE_IMM8:		return vec4(miniBitsToFloat(s_operand.addr));
	case REG_TYPE_IMM16:	return vec4(unpackHalf2x16(s_imm >> (s_operand.idx << 4)).x);
	case REG_TYPE_IMM32:	return vec4(uintBitsToFloat(s_imm));
	}
}

vec4 apply_reduction(vec4 reg, uint s_reduction)
{
	switch(s_reduction)
	{
	default:			return reg;
	case SRC_RED_LUM:	return vec4( dot(reg.rgb, vec3(0.2125, 0.7154, 0.0721)) );
	case SRC_RED_SUM:	return vec4( reg.r + reg.g + reg.b );
	case SRC_RED_AVG:	return vec4( (reg.r + reg.g + reg.b) * 0.3333 );
	case SRC_RED_MIN:	return vec4( min3(reg.r, reg.g, reg.b) );
	case SRC_RED_MAX:	return vec4( max3(reg.r, reg.g, reg.b) );
	case SRC_RED_MAG:	return vec4( fastLength(reg.rgb) );
	}
}

vec4 apply_unary(vec4 reg, uint s_unary)
{
	switch (s_unary)
	{
	default:
	case SRC_UNARY_NONE:	return             reg;
	case SRC_UNARY_NEG:		return            -reg;
	case SRC_UNARY_INV:		return       1.0 - reg;
	case SRC_UNARY_RCP:		return fastRcpNR0(reg);
	}
}

vec4 read_src(vm_src s_operand, vm_instr s_ir)
{
	// fetch the relevant register or immediate value
	vec4 reg = fetch_reg(s_operand, s_ir.imm);

	// apply swizzle
	reg = swizzle_reg(reg, s_operand.swizzle);
	
	// branchless scale + bias
	reg = reg * aScaleBias[s_operand.scale_bias].x + aScaleBias[s_operand.scale_bias].y;
	
	// modifiers
	if( s_operand.absolute)	reg = abs(reg);
	
	// unary op
	reg = apply_unary(reg, s_operand.unary);

	return apply_reduction(reg, s_operand.reduction);
}

vec4 read_src0(vm_instr s_ir)
{
	return read_src(s_ir.src0, s_ir);
}

vec4 read_src1(vm_instr s_ir)
{
	return read_src(s_ir.src1, s_ir);
}

vec4 read_src2(vm_instr s_ir)
{
	return read_src(s_ir.src2, s_ir);
}

void write_reg(vm_instr s_ir, vec4 reg)
{
	// clear the masked bits
	r[s_ir.dst.addr] &= ~s_ir.dst.mask;

	// swizzle for the destination
	//reg = swizzle_reg(reg, s_ir.dst.swizzle);

	// branchless multiplier
	reg *= aScaleBias[s_ir.dst.multiplier].x;

	// modifiers
	if (s_ir.dst.absolute)	reg = abs(reg);
	if (s_ir.sat)			reg = saturate(reg);
	if (s_ir.dst.negate)	reg = -reg;

	// encode
	uint p = encode_reg(reg, s_ir.dst.fmt);

	// write the masked bits
	r[s_ir.dst.addr] |= (p & s_ir.dst.mask);
}

vec4 read_dest(vm_instr s_ir)
{
	return decode_reg(r[s_ir.dst.addr], s_ir.dst.fmt);
}


#endif
